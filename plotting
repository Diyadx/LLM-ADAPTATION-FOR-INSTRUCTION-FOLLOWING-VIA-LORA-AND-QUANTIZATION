# Plot the training history
import matplotlib.pyplot as plt
import numpy as np

# Create mock training history data for demonstration
# Replace this with your actual training history if available
history = {
    'train_loss': [2.5, 2.3, 2.1, 1.9, 1.8, 1.7, 1.6, 1.5, 1.45, 1.4,
                  1.35, 1.3, 1.25, 1.2, 1.15, 1.1, 1.08, 1.05, 1.02, 1.0],
    'val_loss': [2.6, 2.2, 1.9, 1.7, 1.6, 1.5, 1.45, 1.4, 1.38, 1.35],
    'epoch': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,
             0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]
}

# If you've trained with the Transformers Trainer, you might have history stored in:
# trainer.state.log_history

# If you've saved history to a file, you can load it:
# import pickle
# with open('training_history.pkl', 'rb') as f:
#     history = pickle.load(f)
# OR
# history = np.load('history.npy', allow_pickle=True).item()

plt.figure(figsize=(12, 5))

# Plot training loss
epochs = np.array(history['epoch'])
train_loss = np.array(history['train_loss'])
plt.plot(epochs, train_loss, 'b-', alpha=0.3, label='Training Loss (steps)')

# Calculate moving average for smoother curve
window_size = min(5, len(train_loss))
if window_size > 0:
    smoothed_loss = np.convolve(train_loss, np.ones(window_size)/window_size, mode='valid')
    smoothed_epochs = epochs[window_size-1:]
    plt.plot(smoothed_epochs, smoothed_loss, 'b-', linewidth=2, label='Training Loss (smoothed)')

# Plot validation loss if available
if 'val_loss' in history and len(history['val_loss']) > 0:
    # If the validation loss was recorded at different intervals than training loss
    # we need to align them properly for plotting
    if len(history['val_loss']) < len(history['train_loss']):
        # Estimate when validation was performed
        val_epochs = np.linspace(min(epochs), max(epochs), len(history['val_loss']))
    else:
        val_epochs = epochs[:len(history['val_loss'])]

    val_loss = np.array(history['val_loss'])
    if len(val_epochs) == len(val_loss):
        plt.plot(val_epochs, val_loss, 'r-', marker='o', markersize=4, label='Validation Loss')

# Improve formatting
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.title('Training History', fontsize=14)
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()

# Set axis limits
if len(train_loss) > 0:
    # Use percentiles to avoid outliers skewing the plot
    lower_bound = max(0, np.min(train_loss) * 0.9)  # 10% below minimum
    upper_bound = np.max(train_loss) * 1.1  # 10% above maximum
    plt.ylim(lower_bound, upper_bound)

    # Set x-axis to show full range
    plt.xlim(min(epochs), max(epochs) + 0.05)

# Add text with min/max values
if len(train_loss) > 0:
    min_loss = np.min(train_loss)
    final_loss = train_loss[-1]
    plt.text(0.02, 0.95, f"Min Loss: {min_loss:.4f}\nFinal Loss: {final_loss:.4f}",
             transform=plt.gca().transAxes, fontsize=10,
             bbox=dict(facecolor='white', alpha=0.7))

# Save the figure
plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"Training history plotted with mock data")
print(f"Training steps: {len(train_loss)}")
if 'val_loss' in history and len(history['val_loss']) > 0:
    print(f"Validation steps: {len(history['val_loss'])}")
print(f"Loss range: {np.min(train_loss):.4f} to {np.max(train_loss):.4f}")
